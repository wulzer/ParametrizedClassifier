{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Random Seed: 1322 ===========\n"
     ]
    }
   ],
   "source": [
    "from OurTrainingTools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurCDModel(nn.Module):\n",
    "### Defines the  model with parametrized discriminant. Only quadratic dependence on a single parameter is implemented.\n",
    "### Input is the architecture (list of integers, the last one being equal to 1) and the activation type ('ReLU' or 'Sigmoid')\n",
    "    def __init__(self, NumberOfParameters, AR = [1, 3, 3, 1] , AF = 'ReLU'):               \n",
    "        super(OurCDModel, self).__init__() \n",
    "        ValidActivationFunctions = {'ReLU': torch.relu, 'Sigmoid': torch.sigmoid}\n",
    "        try:\n",
    "            self.ActivationFunction = ValidActivationFunctions[AF]\n",
    "        except KeyError:\n",
    "            print('The activation function specified is not valid. Allowed activations are %s.'\n",
    "                 %str(list(ValidActivationFunctions.keys())))\n",
    "            print('Will use ReLU.')\n",
    "            self.ActivationFunction = torch.relu            \n",
    "        if type(AR) == list:\n",
    "            if( ( all(isinstance(n, int) for n in AR)) and ( AR[-1] == 1) ):\n",
    "                self.Architecture = AR\n",
    "            else:\n",
    "                print('Architecture should be a list of integers, the last one should be 1.')\n",
    "                raise ValueError             \n",
    "        else:\n",
    "            print('Architecture should be a list !')\n",
    "            raise ValueError\n",
    "        self.NumberOfParameters = NumberOfParameters\n",
    "\n",
    "### Define Layers\n",
    "        self.NumberOfNetworks = int((2+NumberOfParameters)*(1+NumberOfParameters)/2)-1\n",
    "        LinearLayers = [([nn.Linear(self.Architecture[i], self.Architecture[i+1]) \\\n",
    "                                  for i in range(len(self.Architecture)-1)])\\\n",
    "                        for n in range(self.NumberOfNetworks)]\n",
    "        LinearLayers = [Layer for SubLayerList in LinearLayers for Layer in SubLayerList]\n",
    "        self.LinearLayers = nn.ModuleList(LinearLayers)\n",
    "        \n",
    "    def Forward(self, Data, Parameters):\n",
    "### Forward Function. Performs Preprocessing, returns F = rho/(1+rho) in [0,1], where rho is quadratically parametrized.\n",
    "        # Checking that data has the right input dimension\n",
    "        InputDimension = self.Architecture[0]\n",
    "        if Data.size(1) != InputDimension:\n",
    "            print('Dimensions of the data and the network input mismatch: data: %d, model: %d'\n",
    "                  %(Data.size(1), InputDimension))\n",
    "            raise ValueError\n",
    "\n",
    "        # Checking that preprocess has been initialised\n",
    "        if not hasattr(self, 'Shift'):\n",
    "            print('Please initialize preprocess parameters!')\n",
    "            raise ValueError\n",
    "        with torch.no_grad(): \n",
    "            Data, Parameters = self.Preprocess(Data, Parameters)  \n",
    "        \n",
    "        NumberOfLayers, NumberOfEvents = len(self.Architecture)-1, Data.size(0)\n",
    "        EntryIterator, NetworkIterator = 0, -1\n",
    "        MatrixLT = torch.zeros([NumberOfEvents, (self.NumberOfParameters+1)**2], dtype=Data.dtype)\n",
    "        \n",
    "        if Data.is_cuda:\n",
    "            MatrixLT = OurCudaTensor(MatrixLT)\n",
    "        \n",
    "        for i in range(self.NumberOfParameters+1):\n",
    "            EntryIterator += i\n",
    "            DiagonalEntry = True\n",
    "            for j in range(self.NumberOfParameters+1-i):\n",
    "                if NetworkIterator == -1:\n",
    "                    MatrixLT[:, EntryIterator] = torch.ones(NumberOfEvents)\n",
    "                    #print('Entry: %d, Layer: ones, DiagonalEntry: %s'%(EntryIterator,\n",
    "                    #                                                str(DiagonalEntry)))\n",
    "                else:\n",
    "                    x = Data\n",
    "                    for Layer in self.LinearLayers[NumberOfLayers*NetworkIterator:\\\n",
    "                                                  NumberOfLayers*(NetworkIterator+1)-1]:\n",
    "                        x = self.ActivationFunction(Layer(x))\n",
    "                    x = self.LinearLayers[NumberOfLayers*(NetworkIterator+1)-1](x).squeeze()\n",
    "                    MatrixLT[:, EntryIterator] = torch.exp(x) if DiagonalEntry else x\n",
    "                    #print('Entry: %d, Layer: %d, DiagonalEntry: %s'%(EntryIterator, NetworkIterator, \n",
    "                    #                                                str(DiagonalEntry)))\n",
    "                EntryIterator += 1\n",
    "                NetworkIterator += 1\n",
    "                DiagonalEntry = False\n",
    "        #print('MatrixLT: '+str(MatrixLT.is_cuda))\n",
    "        #print('Parameters: '+str(Parameters.is_cuda))\n",
    "\n",
    "        MatrixLT = MatrixLT.reshape([-1, self.NumberOfParameters+1, self.NumberOfParameters+1])\n",
    "        MatrixLTP = MatrixLT.matmul(Parameters.reshape([NumberOfEvents, self.NumberOfParameters+1, 1]))\n",
    "        rho = MatrixLTP.permute([0, 2, 1]).matmul(MatrixLTP).squeeze()\n",
    "        \n",
    "        return (rho.div(1.+rho)).view(-1, 1)\n",
    "    \n",
    "    def GetL1Bound(self, L1perUnit):\n",
    "        self.L1perUnit = L1perUnit\n",
    "    \n",
    "    def ClipL1Norm(self):\n",
    "### Clip the weights      \n",
    "        def ClipL1NormLayer(DesignatedL1Max, Layer, Counter):\n",
    "            if Counter == 1:\n",
    "                ### this avoids clipping the first layer\n",
    "                return\n",
    "            L1 = Layer.weight.abs().sum()\n",
    "            Layer.weight.masked_scatter_(L1 > DesignatedL1Max, \n",
    "                                        Layer.weight*(DesignatedL1Max/L1))\n",
    "            return\n",
    "        \n",
    "        Counter = 0\n",
    "        for m in self.children():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                Counter += 1\n",
    "                with torch.no_grad():\n",
    "                    DesignatedL1Max = m.weight.size(0)*m.weight.size(1)*self.L1perUnit\n",
    "                    ClipL1NormLayer(DesignatedL1Max, m, Counter)\n",
    "            else:\n",
    "                for mm in m:\n",
    "                    Counter +=1\n",
    "                    with torch.no_grad():\n",
    "                        DesignatedL1Max = mm.weight.size(0)*m.weight.size(1)*self.L1perUnit\n",
    "                        ClipL1NormLayer(DesignatedL1Max, mm, Counter)\n",
    "        return \n",
    "    \n",
    "    def DistributionRatio(self, points):\n",
    "### This is rho. I.e., after training, the estimator of the distribution ratio.\n",
    "        with torch.no_grad():\n",
    "            F = self(points)\n",
    "        return F/(1-F)\n",
    "\n",
    "    def InitPreprocess(self, Data, Parameters):\n",
    "### This can be run only ONCE to initialize the preprocess (shift and scaling) parameters\n",
    "### Takes as input the training Data and the training Parameters as Torch tensors.\n",
    "        if not hasattr(self, 'Scaling'):\n",
    "            print('Initializing Preprocesses Variables')\n",
    "            self.Scaling = Data.std(0)\n",
    "            self.Shift = Data.mean(0)\n",
    "            self.ParameterScaling = Parameters.std(0)  \n",
    "        else: print('Preprocess can be initialized only once. Parameters unchanged.')\n",
    "            \n",
    "    def Preprocess(self, Data, Parameters):\n",
    "### Returns scaled/shifted data and parameters\n",
    "### Takes as input Data and Parameters as Torch tensors.\n",
    "        if  not hasattr(self, 'Scaling'): print('Preprocess parameters are not initialized.')\n",
    "        Data = (Data - self.Shift)/self.Scaling\n",
    "        Parameters = Parameters/self.ParameterScaling\n",
    "        Ones = torch.ones([Parameters.size(0),1], dtype=Parameters.dtype)\n",
    "        if Parameters.is_cuda:\n",
    "            Ones = Ones.cuda()\n",
    "        Parameters = torch.cat([Ones, Parameters.reshape(Data.size(0), -1)], dim=1)\n",
    "        return Data, Parameters\n",
    "    \n",
    "    def Save(self, Name, Folder, csvFormat=False):\n",
    "### Saves the model in Folder/Name\n",
    "        FileName = Folder + Name + '.pth'\n",
    "        torch.save({'StateDict': self.state_dict(), \n",
    "                   'Scaling': self.Scaling,\n",
    "                   'Shift': self.Shift,\n",
    "                   'ParameterScaling': self.ParameterScaling}, \n",
    "                   FileName)\n",
    "        print('Model successfully saved.')\n",
    "        print('Path: %s'%str(FileName))\n",
    "        \n",
    "        if csvFormat:\n",
    "            modelparams = [w.detach().tolist() for w in self.parameters()]\n",
    "            np.savetxt(Folder + Name + ' (StateDict).csv', modelparams, '%s')\n",
    "            statistics = [self.Shift.detach().tolist(), self.Scaling.detach().tolist(),\n",
    "                         self.ParameterScaling.detach().tolist()]\n",
    "            np.savetxt(Folder + Name + ' (Statistics).csv', statistics, '%s')\n",
    "    \n",
    "    def Load(self, Name, Folder):\n",
    "### Loads the model from Folder/Name\n",
    "        FileName = Folder + Name + '.pth'\n",
    "        try:\n",
    "            IncompatibleKeys = self.load_state_dict(torch.load(FileName)['StateDict'])\n",
    "        except KeyError:\n",
    "            print('No state dictionary saved. Loading model failed.')\n",
    "            return \n",
    "        \n",
    "        if list(IncompatibleKeys)[0]:\n",
    "            print('Missing Keys: %s'%str(list(IncompatibleKeys)[0]))\n",
    "            print('Loading model failed. ')\n",
    "            return \n",
    "        \n",
    "        if list(IncompatibleKeys)[1]:\n",
    "            print('Unexpected Keys: %s'%str(list(IncompatibleKeys)[0]))\n",
    "            print('Loading model failed. ')\n",
    "            return \n",
    "        \n",
    "        self.Scaling = torch.load(FileName)['Scaling']\n",
    "        self.Shift = torch.load(FileName)['Shift']\n",
    "        self.ParameterScaling = torch.load(FileName)['ParameterScaling']\n",
    "        \n",
    "        print('Model successfully loaded.')\n",
    "        print('Path: %s'%str(FileName))\n",
    "        \n",
    "    def Report(self): ### is it possibe to check if the model is in double?\n",
    "        print('\\nModel Report:')\n",
    "        print('Preprocess Initialized: ' + str(hasattr(self, 'Shift')))\n",
    "        print('Architecture: ' + str(self.Architecture))\n",
    "        print('Loss Function: ' + 'Quadratic')\n",
    "        print('Activation: ' + str(self.ActivationFunction))\n",
    "        \n",
    "    def cuda(self):\n",
    "        nn.Module.cuda(self)\n",
    "        self.Shift = self.Shift.cuda()\n",
    "        self.Scaling = self.Scaling.cuda()\n",
    "        self.ParameterScaling = self.ParameterScaling.cuda()\n",
    "        \n",
    "    def cpu(self):\n",
    "        self.Shift = self.Shift.cpu()\n",
    "        self.Scaling = self.Scaling.cpu()\n",
    "        self.ParameterScaling = self.ParameterScaling.cpu()\n",
    "        return nn.Module.cpu(self)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Preprocesses Variables\n"
     ]
    }
   ],
   "source": [
    "tempdata = torch.empty([100, 8]).normal_()\n",
    "tempparam = torch.cat([torch.ones([50, 1]).mul(torch.tensor([1., 3., 0.,])),\n",
    "                      torch.ones([50, 1]).mul(torch.tensor([2., 1., 5.,]))])\n",
    "tempmodel = OurCDModel(NumberOfParameters=3, AR=[8,32,32,32,1])\n",
    "tempmodel.InitPreprocess(tempdata, tempparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry: 0, Layer: ones, DiagonalEntry: True\n",
      "Entry: 1, Layer: 0, DiagonalEntry: False\n",
      "Entry: 2, Layer: 1, DiagonalEntry: False\n",
      "Entry: 3, Layer: 2, DiagonalEntry: False\n",
      "Entry: 5, Layer: 3, DiagonalEntry: True\n",
      "Entry: 6, Layer: 4, DiagonalEntry: False\n",
      "Entry: 7, Layer: 5, DiagonalEntry: False\n",
      "Entry: 10, Layer: 6, DiagonalEntry: True\n",
      "Entry: 11, Layer: 7, DiagonalEntry: False\n",
      "Entry: 15, Layer: 8, DiagonalEntry: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OurCDModel(\n",
       "  (LinearLayers): ModuleList(\n",
       "    (0): Linear(in_features=8, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (4): Linear(in_features=8, out_features=32, bias=True)\n",
       "    (5): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (6): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (7): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (8): Linear(in_features=8, out_features=32, bias=True)\n",
       "    (9): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (10): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (11): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (12): Linear(in_features=8, out_features=32, bias=True)\n",
       "    (13): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (14): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (15): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (16): Linear(in_features=8, out_features=32, bias=True)\n",
       "    (17): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (18): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (19): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (20): Linear(in_features=8, out_features=32, bias=True)\n",
       "    (21): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (22): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (23): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (24): Linear(in_features=8, out_features=32, bias=True)\n",
       "    (25): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (26): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (27): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (28): Linear(in_features=8, out_features=32, bias=True)\n",
       "    (29): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (30): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (31): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (32): Linear(in_features=8, out_features=32, bias=True)\n",
       "    (33): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (34): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (35): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempmodel.Forward(tempdata, tempparam)\n",
    "tempmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data Files for Process: W+Z, with new physics Parameters: ['GW[TeV**-2]']\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChPgw20.h5\n",
      "##### File Info:\n",
      "GW = 0.2[Tev**-2] data, showering on. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ, PtWZ, PtW, mz2, mw2}, weight}. Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChP290gw20.dat\n",
      " File with charge = 1\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChPgw5.h5\n",
      "##### File Info:\n",
      "GW = 0.05[Tev**-2] data, showering on. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ, PtWZ, PtW, mz2, mw2}, weight}. Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChP290gw5.dat\n",
      " File with charge = 1\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChPgw10.h5\n",
      "##### File Info:\n",
      "GW = 0.1[Tev**-2] data, showering on. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ, PtWZ, PtW, mz2, mw2}, weight}. Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChP290gw10.dat\n",
      " File with charge = 1\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChPgwm20.h5\n",
      "##### File Info:\n",
      "GW = -0.2[Tev**-2] data, showering on. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ, PtWZ, PtW, mz2, mw2}, weight}. Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChP290gwm20.dat\n",
      " File with charge = 1\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChPgwm5.h5\n",
      "##### File Info:\n",
      "GW = -0.05[Tev**-2] data, showering on. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ, PtWZ, PtW, mz2, mw2}, weight}. Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChP290gwm5.dat\n",
      " File with charge = 1\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChPgwm10.h5\n",
      "##### File Info:\n",
      "GW = -0.1[Tev**-2] data, showering on. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ, PtWZ, PtW, mz2, mw2}, weight}. Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChP290gwm10.dat\n",
      " File with charge = 1\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/SMData/ChPsm.h5\n",
      "##### File Info:\n",
      "SM = 0.[Tev**-2] data, showering on. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ, PtWZ, PtW, mz2, mw2}, weight}. Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChP290sm.dat\n",
      " File with charge = 1\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/SMData/ChPsm2.h5\n",
      "##### File Info:\n",
      "SM = 0.[Tev**-2] data, showering on. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ, PtWZ, PtW, mz2, mw2}, weight}. Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChP290sm2.dat\n",
      " File with charge = 1\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/SMData/ChPsm3.h5\n",
      "##### File Info:\n",
      "SM = 0.[Tev**-2] data, showering on. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ, PtWZ, PtW, mz2, mw2}, weight}. Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChP290sm3.dat\n",
      " File with charge = 1\n",
      "#####\n",
      "\n",
      "Loaded SM Files:\n",
      "  ['GW[TeV**-2]']    #Data    XS[pb](avg.w)\n",
      "-----------------  -------  ---------------\n",
      "                0   502045      0.000285306\n",
      "                0   502419      0.000286202\n",
      "                0   501826      0.0002855\n",
      "\n",
      "Loaded BSM Files:\n",
      "  ['GW[TeV**-2]']    #Data    XS[pb](avg.w)\n",
      "-----------------  -------  ---------------\n",
      "             0.2    851787      0.000588816\n",
      "             0.05   529911      0.000302704\n",
      "             0.1    604497      0.000357023\n",
      "            -0.2    865711      0.000623018\n",
      "            -0.05   531605      0.000309923\n",
      "            -0.1    611890      0.000373267\n",
      "\n",
      "Paired BSM/SM Datasets:\n",
      "\n",
      "  ['GW[TeV**-2]']    #Ev.BSM    #Ev.SM    Check\n",
      "-----------------  ---------  --------  -------\n",
      "             0.2      500000    251048   499836\n",
      "             0.05     500000    251048   500667\n",
      "             0.1      500000    251048   499786\n",
      "            -0.2      500000    251048   499420\n",
      "            -0.05     500000    251048   500651\n",
      "            -0.1      500000    251048   499640\n",
      "Initializing Preprocesses Variables\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (30) : unknown error at /opt/conda/conda-bld/pytorch_1556653114079/work/aten/src/THC/THCGeneral.cpp:51",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2fd7f0a81512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m OT.Train(MD, Data = Data, Parameters = ParVal, Labels=Labels, Weights= Weights, bs = 100000,\n\u001b[0;32m---> 23\u001b[0;31m         Name = 'ChPgw2,5,10, (500k, CD), ', Folder = os.getcwd()+'/TrainedModels/')\n\u001b[0m",
      "\u001b[0;32m~/Documents/ParametrizedClassifier/OurTrainingTools.py\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(self, model, Data, Parameters, Labels, Weights, bs, L1perUnit, UseGPU, Name, Folder, WeightClipping, L1Max)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0mtempmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0mtempmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m         \u001b[0mtempData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOurCudaTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0mtempParameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOurCudaTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-9e6465af2bc3>\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mShift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mShift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScaling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScaling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    162\u001b[0m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0m_cudart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudaGetErrorName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (30) : unknown error at /opt/conda/conda-bld/pytorch_1556653114079/work/aten/src/THC/THCGeneral.cpp:51"
     ]
    }
   ],
   "source": [
    "td = OurTrainingData(['/data3/Training/TrainingData/SMData/ChPsm.h5',\n",
    "                     '/data3/Training/TrainingData/SMData/ChPsm2.h5',\n",
    "                     '/data3/Training/TrainingData/SMData/ChPsm3.h5',],\n",
    "                    ['/data3/Training/TrainingData/GWData/ChPgw20.h5',\n",
    "                     '/data3/Training/TrainingData/GWData/ChPgw5.h5',\n",
    "                     '/data3/Training/TrainingData/GWData/ChPgw10.h5',\n",
    "                     '/data3/Training/TrainingData/GWData/ChPgwm20.h5',\n",
    "                     '/data3/Training/TrainingData/GWData/ChPgwm5.h5',\n",
    "                     '/data3/Training/TrainingData/GWData/ChPgwm10.h5',],\n",
    "                     process = 'W+Z', parameters =['GW[TeV**-2]'], \n",
    "                     SMNLimits=int(3e6),\n",
    "                     BSMNLimits=int(5e5))\n",
    "\n",
    "Data, ParVal, Labels, Weights = td.Data[:, :8], td.ParVal, td.Labels, td.Weights\n",
    "MD = OurCDModel(NumberOfParameters=1, AR=[8,32,32,32,1])\n",
    "MD.double()\n",
    "MD.InitPreprocess(Data, ParVal)\n",
    "\n",
    "OT = OurTrainer(NumEpochs = int(1e4))\n",
    "OT.SetSaveAfterEpochs([10,100,500]+list(range(1000, 11000, 1000)))\n",
    "\n",
    "OT.Train(MD, Data = Data, Parameters = ParVal, Labels=Labels, Weights= Weights, bs = 100000,\n",
    "        Name = 'ChPgw2,5,10, (500k, CD), ', Folder = os.getcwd()+'/TrainedModels/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data Files for Process: W-Z, with new physics Parameters: ['GW[TeV**-2]']\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChMgw20.h5\n",
      "##### File Info:\n",
      "GW = 0.2[Tev**-2] data, showering on. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ, PtWZ, PtW, mz2, mw2}, weight}. Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChM290gw20.dat\n",
      " File with charge = -1\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChMgw5.h5\n",
      "##### File Info:\n",
      "GW = 0.05[Tev**-2] data, showering on. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ, PtWZ, PtW, mz2, mw2}, weight}. Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChM290gw5.dat\n",
      " File with charge = -1\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChMgw10.h5\n",
      "##### File Info:\n",
      "GW = 0.1[Tev**-2] data, showering on. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ, PtWZ, PtW, mz2, mw2}, weight}. Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChM290gw10.dat\n",
      " File with charge = -1\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChMgwm20.h5\n",
      "##### File Info:\n",
      "GW = -0.2[Tev**-2] data, showering on. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ, PtWZ, PtW, mz2, mw2}, weight}. Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChM290gwm20.dat\n",
      " File with charge = -1\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChMgwm5.h5\n",
      "##### File Info:\n",
      "GW = -0.05[Tev**-2] data, showering on. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ, PtWZ, PtW, mz2, mw2}, weight}. Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChM290gwm5.dat\n",
      " File with charge = -1\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChMgwm10.h5\n",
      "##### File Info:\n",
      "GW = -0.1[Tev**-2] data, showering on. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ, PtWZ, PtW, mz2, mw2}, weight}. Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChM290gwm10.dat\n",
      " File with charge = -1\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/SMData/ChMsm.h5\n",
      "##### File Info:\n",
      "SM = 0.[Tev**-2] data, showering on. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ, PtWZ, PtW, mz2, mw2}, weight}. Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChM290sm.dat\n",
      " File with charge = -1\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/SMData/ChMsm2.h5\n",
      "##### File Info:\n",
      "SM = 0.[Tev**-2] data, showering on. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ, PtWZ, PtW, mz2, mw2}, weight}. Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChM290sm2.dat\n",
      " File with charge = -1\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/SMData/ChMsm3.h5\n",
      "##### File Info:\n",
      "SM = 0.[Tev**-2] data, showering on. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ, PtWZ, PtW, mz2, mw2}, weight}. Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChM290sm3.dat\n",
      " File with charge = -1\n",
      "#####\n",
      "\n",
      "Loaded SM Files:\n",
      "  ['GW[TeV**-2]']    #Data    XS[pb](avg.w)\n",
      "-----------------  -------  ---------------\n",
      "                0   445751      0.000143144\n",
      "                0   445619      0.000143272\n",
      "                0   445576      0.000142907\n",
      "\n",
      "Loaded BSM Files:\n",
      "  ['GW[TeV**-2]']    #Data    XS[pb](avg.w)\n",
      "-----------------  -------  ---------------\n",
      "             0.2    725955      0.000270203\n",
      "             0.05   466114      0.000149661\n",
      "             0.1    524530      0.000172396\n",
      "            -0.2    742423      0.000286968\n",
      "            -0.05   469263      0.00015336\n",
      "            -0.1    532722      0.000181293\n",
      "\n",
      "Paired BSM/SM Datasets:\n",
      "\n",
      "  ['GW[TeV**-2]']    #Ev.BSM    #Ev.SM    Check\n",
      "-----------------  ---------  --------  -------\n",
      "             0.2      500000    227729   499494\n",
      "             0.05     466114    212296   466218\n",
      "             0.1      500000    227729   499932\n",
      "            -0.2      500000    227729   500075\n",
      "            -0.05     469263    213730   469017\n",
      "            -0.1      500000    227729   500639\n",
      "Initializing Preprocesses Variables\n"
     ]
    }
   ],
   "source": [
    "td = OurTrainingData(['/data3/Training/TrainingData/SMData/ChMsm.h5',\n",
    "                     '/data3/Training/TrainingData/SMData/ChMsm2.h5',\n",
    "                     '/data3/Training/TrainingData/SMData/ChMsm3.h5',],\n",
    "                    ['/data3/Training/TrainingData/GWData/ChMgw20.h5',\n",
    "                     '/data3/Training/TrainingData/GWData/ChMgw5.h5',\n",
    "                     '/data3/Training/TrainingData/GWData/ChMgw10.h5',\n",
    "                     '/data3/Training/TrainingData/GWData/ChMgwm20.h5',\n",
    "                     '/data3/Training/TrainingData/GWData/ChMgwm5.h5',\n",
    "                     '/data3/Training/TrainingData/GWData/ChMgwm10.h5',],\n",
    "                     process = 'W-Z', parameters =['GW[TeV**-2]'], \n",
    "                     SMNLimits=int(3e6),\n",
    "                     BSMNLimits=int(5e5))\n",
    "\n",
    "Data, ParVal, Labels, Weights = td.Data[:, :8], td.ParVal, td.Labels, td.Weights\n",
    "MD = OurCDModel(NumberOfParameters=1, AR=[8,32,32,32,1])\n",
    "MD.double()\n",
    "MD.InitPreprocess(Data, ParVal)\n",
    "\n",
    "OT = OurTrainer(NumEpochs = int(1e4))\n",
    "OT.SetSaveAfterEpochs([10,100,500]+list(range(1000, 11000, 1000)))\n",
    "\n",
    "OT.Train(MD, Data = Data, Parameters = ParVal, Labels=Labels, Weights= Weights, bs = 100000,\n",
    "        Name = 'ChMgw2,5,10, (500k, CD), ', Folder = os.getcwd()+'/TrainedModels/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([53.2776, 41.2998, 39.7028, 60.2778, 37.5379, 50.8842, 40.7845, 41.8562,\n",
       "        41.7262, 57.7348, 62.5857, 64.4010, 40.5552, 36.0387, 41.7204, 44.0750,\n",
       "        41.8498, 55.1948, 57.6788, 33.6665, 38.0422, 78.1223, 34.6115, 55.5912,\n",
       "        52.7553, 29.8227, 45.6006, 56.3874, 29.8103, 46.8122, 55.6364, 38.1525,\n",
       "        47.8337, 40.9304, 45.7424, 25.9865, 48.1553, 60.4051, 72.2461, 59.1649,\n",
       "        30.3844, 46.5015, 40.5201, 40.7097, 55.5965, 41.4380, 54.1305, 43.2585,\n",
       "        46.9714, 39.4395, 62.3753, 74.8668, 54.3242, 34.5350, 47.0982, 48.9572,\n",
       "        41.5068, 39.7230, 44.4457, 53.8537, 73.3045, 55.2483, 40.0775, 39.9372,\n",
       "        49.8916, 48.3826, 34.7451, 23.2622, 54.1850, 40.4493, 48.1900, 54.7582,\n",
       "        49.6336, 40.2133, 49.5574, 36.5985, 46.7742, 59.3095, 41.3831, 42.0143,\n",
       "        45.2201, 38.8211, 69.8754, 37.5511, 47.5282, 41.5546, 43.2678, 59.7412,\n",
       "        25.9005, 38.3847, 63.8126, 33.0527, 52.6752, 63.7158, 58.9484, 36.8365,\n",
       "        49.9637, 33.6771, 63.9414, 52.8860], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MatrixLTP = MatrixLT.matmul(TempParameters.reshape([100, 3, 1]))\n",
    "MatrixLTP.permute([0, 2, 1]).matmul(MatrixLTP).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
