{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Datasets with Parameters: ['GW[TeV**-2]']\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChPsm.h5\n",
      "##### File Info:\n",
      "GW data, showering on. \n",
      "Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChPLong290sm.dat.gz\n",
      " File with charge = 1 and {GW, Gphi} = {0., 0.}\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChPgw10.h5\n",
      "##### File Info:\n",
      "GW data, showering on. \n",
      "Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChPLong290gw10.dat.gz\n",
      " File with charge = 1 and {GW, Gphi} = {0.1, 0.}\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChPgw5.h5\n",
      "##### File Info:\n",
      "GW data, showering on. \n",
      "Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChPLong290gw5.dat.gz\n",
      " File with charge = 1 and {GW, Gphi} = {0.05, 0.}\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChPgw2.h5\n",
      "##### File Info:\n",
      "GW data, showering on. \n",
      "Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChPLong290gw2.dat.gz\n",
      " File with charge = 1 and {GW, Gphi} = {0.02, 0.}\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChPgwm10.h5\n",
      "##### File Info:\n",
      "GW data, showering on. \n",
      "Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChPLong290gwm10.dat.gz\n",
      " File with charge = 1 and {GW, Gphi} = {-0.1, 0.}\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChPgwm5.h5\n",
      "##### File Info:\n",
      "GW data, showering on. \n",
      "Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChPLong290gwm5.dat.gz\n",
      " File with charge = 1 and {GW, Gphi} = {-0.05, 0.}\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChPgwm2.h5\n",
      "##### File Info:\n",
      "GW data, showering on. \n",
      "Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChPLong290gwm2.dat.gz\n",
      " File with charge = 1 and {GW, Gphi} = {-0.02, 0.}\n",
      "#####\n",
      "0.0003217710, 0.0003227415, 0.0003229768\n",
      "['0.0003224935']\n",
      "\n",
      "Loaded Files:\n",
      "\n",
      "  ['GW[TeV**-2]']    #Events    XS[pb](avg.w)\n",
      "-----------------  ---------  ---------------\n",
      "                0     566980      0.000322493\n",
      " \n",
      "  ['GW[TeV**-2]']    #Events    XS[pb](avg.w)\n",
      "-----------------  ---------  ---------------\n",
      "             0.1      200000      0.000404072\n",
      "             0.05     200000      0.000340505\n",
      "             0.02     200000      0.000324063\n",
      "            -0.1      200000      0.000423358\n",
      "            -0.05     200000      0.000351064\n",
      "            -0.02     200000      0.000329051\n",
      "\n",
      "Paired BSM/SM Datasets:\n",
      "\n",
      "  ['GW[TeV**-2]']    #Ev.BSM    #Ev.SM    sum.w BSM\\/XSBSM    sum.w SM\\/XSSM     avg.w SM\n",
      "-----------------  ---------  --------  ------------------  ----------------  -----------\n",
      "             0.1      200000     94496              200073            199552  0.000681026\n",
      "             0.05     200000     94496              200058            200154  0.00068308\n",
      "             0.02     200000     94496              199971            200300  0.000683578\n",
      "            -0.1      200000     94496              199869            199573  0.000681096\n",
      "            -0.05     200000     94496              200061            200194  0.000683217\n",
      "            -0.02     200000     94496              200349            200227  0.00068333\n"
     ]
    }
   ],
   "source": [
    "trainingdata = OurTrainingData(['/data3/Training/TrainingData/GWData/ChPsm.h5'],\n",
    "                    ['/data3/Training/TrainingData/GWData/ChPgw10.h5',\n",
    "                     '/data3/Training/TrainingData/GWData/ChPgw5.h5',\n",
    "                     '/data3/Training/TrainingData/GWData/ChPgw2.h5',\n",
    "                    '/data3/Training/TrainingData/GWData/ChPgwm10.h5',\n",
    "                     '/data3/Training/TrainingData/GWData/ChPgwm5.h5',\n",
    "                     '/data3/Training/TrainingData/GWData/ChPgwm2.h5',], ['GW[TeV**-2]'],\n",
    "                    BSMNLimits=int(2e5))\n",
    "\n",
    "trainingdata.Report()\n",
    "Data, DataParameters, Labels = trainingdata.Data[:, :8], trainingdata.TrainingParameters, trainingdata.Labels\n",
    "Weights = trainingdata.Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture = [8, 32, 32, 32, 1]\n",
      "Activation function = ReLU\n",
      "Initial learning rate = 0.001\n",
      "Number of epochs = 10000\n",
      "Saving network after epoch(s): [10, 50, 100, 500, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
      "Setting up preprocess statistics.\n",
      "23552\n",
      "63714816\n",
      " =================== BEGINNING TRAIN ==================== \n",
      "Training epoch 10 (took 1.68 sec, time left 0:25:23.954922 sec) loss 0.00011683\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChPgw2,5,10, 10 epoch.pth\n",
      "Training epoch 50 (took 6.47 sec, time left 0:26:32.747201 sec) loss 0.00011484\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChPgw2,5,10, 50 epoch.pth\n",
      "Training epoch 100 (took 8.08 sec, time left 0:26:34.453964 sec) loss 0.00011382\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChPgw2,5,10, 100 epoch.pth\n",
      "Training epoch 500 (took 64.75 sec, time left 0:25:36.454699 sec) loss 0.00011350\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChPgw2,5,10, 500 epoch.pth\n",
      "Training epoch 1000 (took 81.05 sec, time left 0:24:17.325362 sec) loss 0.00011344\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChPgw2,5,10, 1000 epoch.pth\n",
      "Training epoch 2000 (took 162.63 sec, time left 0:21:38.187754 sec) loss 0.00011331\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChPgw2,5,10, 2000 epoch.pth\n",
      "Training epoch 3000 (took 161.25 sec, time left 0:18:53.511133 sec) loss 0.00011318\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChPgw2,5,10, 3000 epoch.pth\n",
      "Training epoch 4000 (took 161.37 sec, time left 0:16:10.706000 sec) loss 0.00011309\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChPgw2,5,10, 4000 epoch.pth\n",
      "Training epoch 5000 (took 161.51 sec, time left 0:13:28.608166 sec) loss 0.00011302\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChPgw2,5,10, 5000 epoch.pth\n",
      "Training epoch 6000 (took 161.45 sec, time left 0:10:46.664822 sec) loss 0.00011297\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChPgw2,5,10, 6000 epoch.pth\n",
      "Training epoch 7000 (took 161.32 sec, time left 0:08:04.799477 sec) loss 0.00011293\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChPgw2,5,10, 7000 epoch.pth\n",
      "Training epoch 8000 (took 161.10 sec, time left 0:05:23.012093 sec) loss 0.00011289\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChPgw2,5,10, 8000 epoch.pth\n",
      "Training epoch 9000 (took 161.27 sec, time left 0:02:41.391776 sec) loss 0.00011286\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChPgw2,5,10, 9000 epoch.pth\n",
      "Training epoch 10000 (took 161.48 sec, time left -1 day, 23:59:59.838452 sec) loss 0.00011283\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChPgw2,5,10, 10000 epoch.pth\n",
      " ===================   END OF TRAIN   =================== \n"
     ]
    }
   ],
   "source": [
    "ModelPath = os.getcwd()\n",
    "\n",
    "model = OurModel([8, 32, 32, 32, 1], 'ReLU')\n",
    "model.SetNumberOfEpochs(int(1e4))\n",
    "model.SetInitialLearningRate(1e-3)\n",
    "model.SetSaveAfterEpoch([10, 50, 100, 500, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000])\n",
    "model.Report()\n",
    "\n",
    "Data, DataParameters = model.Preprocess(Data, DataParameters)\n",
    "Data, DataParameters = Data.float(), DataParameters.float()\n",
    "Labels, Weights = Labels.float(), Weights.float()\n",
    "\n",
    "model.cuda()\n",
    "print(torch.cuda.memory_allocated())\n",
    "Data, DataParameters = Data.cuda(), DataParameters.cuda()\n",
    "print(torch.cuda.memory_allocated())\n",
    "\n",
    "model.Train(Data, DataParameters, Labels, Weights, Name='/ChPgw2,5,10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Datasets with Parameters: ['GW[TeV**-2]']\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChPsm.h5\n",
      "##### File Info:\n",
      "GW data, showering on. \n",
      "Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChPLong290sm.dat.gz\n",
      " File with charge = 1 and {GW, Gphi} = {0., 0.}\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChMgw10.h5\n",
      "##### File Info:\n",
      "GW data, showering on. \n",
      "Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChMLong290gw10.dat.gz\n",
      " File with charge = -1 and {GW, Gphi} = {0.1, 0.}\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChMgw5.h5\n",
      "##### File Info:\n",
      "GW data, showering on. \n",
      "Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChMLong290gw5.dat.gz\n",
      " File with charge = -1 and {GW, Gphi} = {0.05, 0.}\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChMgw2.h5\n",
      "##### File Info:\n",
      "GW data, showering on. \n",
      "Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChMLong290gw2.dat.gz\n",
      " File with charge = -1 and {GW, Gphi} = {0.02, 0.}\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChMgwm10.h5\n",
      "##### File Info:\n",
      "GW data, showering on. \n",
      "Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChMLong290gwm10.dat.gz\n",
      " File with charge = -1 and {GW, Gphi} = {-0.1, 0.}\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChMgwm5.h5\n",
      "##### File Info:\n",
      "GW data, showering on. \n",
      "Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChMLong290gwm5.dat.gz\n",
      " File with charge = -1 and {GW, Gphi} = {-0.05, 0.}\n",
      "#####\n",
      "\n",
      "Reading file .../data3/Training/TrainingData/GWData/ChMgwm2.h5\n",
      "##### File Info:\n",
      "GW data, showering on. \n",
      "Converted from /data3/ConvertMGevents/Showered_Events_for_Training/ChMLong290gwm2.dat.gz\n",
      " File with charge = -1 and {GW, Gphi} = {-0.02, 0.}\n",
      "#####\n",
      "0.0003217710, 0.0003227415, 0.0003229768\n",
      "['0.0003224935']\n",
      "\n",
      "Loaded Files:\n",
      "\n",
      "  ['GW[TeV**-2]']    #Events    XS[pb](avg.w)\n",
      "-----------------  ---------  ---------------\n",
      "                0     566980      0.000322493\n",
      " \n",
      "  ['GW[TeV**-2]']    #Events    XS[pb](avg.w)\n",
      "-----------------  ---------  ---------------\n",
      "             0.1      200000      0.000194143\n",
      "             0.05     200000      0.000167781\n",
      "             0.02     200000      0.000160761\n",
      "            -0.1      200000      0.000203753\n",
      "            -0.05     200000      0.000173\n",
      "            -0.02     200000      0.000163182\n",
      "\n",
      "Paired BSM/SM Datasets:\n",
      "\n",
      "  ['GW[TeV**-2]']    #Ev.BSM    #Ev.SM    sum.w BSM\\/XSBSM    sum.w SM\\/XSSM     avg.w SM\n",
      "-----------------  ---------  --------  ------------------  ----------------  -----------\n",
      "             0.1      200000     94496              199977            199552  0.000681026\n",
      "             0.05     200000     94496              200126            200154  0.00068308\n",
      "             0.02     200000     94496              200010            200300  0.000683578\n",
      "            -0.1      200000     94496              200014            199573  0.000681096\n",
      "            -0.05     200000     94496              200253            200194  0.000683217\n",
      "            -0.02     200000     94496              200001            200227  0.00068333\n"
     ]
    }
   ],
   "source": [
    "trainingdata = OurTrainingData(['/data3/Training/TrainingData/GWData/ChPsm.h5'],\n",
    "                    ['/data3/Training/TrainingData/GWData/ChMgw10.h5',\n",
    "                     '/data3/Training/TrainingData/GWData/ChMgw5.h5',\n",
    "                     '/data3/Training/TrainingData/GWData/ChMgw2.h5',\n",
    "                    '/data3/Training/TrainingData/GWData/ChMgwm10.h5',\n",
    "                     '/data3/Training/TrainingData/GWData/ChMgwm5.h5',\n",
    "                     '/data3/Training/TrainingData/GWData/ChMgwm2.h5',], ['GW[TeV**-2]'],\n",
    "                    BSMNLimits=int(2e5))\n",
    "\n",
    "trainingdata.Report()\n",
    "Data, DataParameters, Labels = trainingdata.Data[:, :8], trainingdata.TrainingParameters, trainingdata.Labels\n",
    "Weights = trainingdata.Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture = [8, 32, 32, 32, 1]\n",
      "Activation function = ReLU\n",
      "Initial learning rate = 0.001\n",
      "Number of epochs = 10000\n",
      "Saving network after epoch(s): [10, 50, 100, 500, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
      "Setting up preprocess statistics.\n",
      "601691648\n",
      "601691648\n",
      " =================== BEGINNING TRAIN ==================== \n",
      "Training epoch 10 (took 1.48 sec, time left 0:22:25.512403 sec) loss 0.00008608\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChMgw2,5,10, 10 epoch.pth\n",
      "Training epoch 50 (took 6.35 sec, time left 0:25:30.823171 sec) loss 0.00008488\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChMgw2,5,10, 50 epoch.pth\n",
      "Training epoch 100 (took 7.97 sec, time left 0:25:51.804871 sec) loss 0.00008477\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChMgw2,5,10, 100 epoch.pth\n",
      "Training epoch 500 (took 63.83 sec, time left 0:25:10.834286 sec) loss 0.00008429\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChMgw2,5,10, 500 epoch.pth\n",
      "Training epoch 1000 (took 79.96 sec, time left 0:23:55.376829 sec) loss 0.00008416\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChMgw2,5,10, 1000 epoch.pth\n",
      "Training epoch 2000 (took 159.90 sec, time left 0:21:17.540947 sec) loss 0.00008399\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChMgw2,5,10, 2000 epoch.pth\n",
      "Training epoch 3000 (took 160.00 sec, time left 0:18:38.535979 sec) loss 0.00008386\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChMgw2,5,10, 3000 epoch.pth\n",
      "Training epoch 4000 (took 159.96 sec, time left 0:15:58.965467 sec) loss 0.00008377\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChMgw2,5,10, 4000 epoch.pth\n",
      "Training epoch 5000 (took 159.93 sec, time left 0:13:19.203242 sec) loss 0.00008370\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChMgw2,5,10, 5000 epoch.pth\n",
      "Training epoch 6000 (took 161.41 sec, time left 0:10:40.366299 sec) loss 0.00008366\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChMgw2,5,10, 6000 epoch.pth\n",
      "Training epoch 7000 (took 161.67 sec, time left 0:08:00.903253 sec) loss 0.00008362\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChMgw2,5,10, 7000 epoch.pth\n",
      "Training epoch 8000 (took 161.47 sec, time left 0:05:20.833290 sec) loss 0.00008360\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChMgw2,5,10, 8000 epoch.pth\n",
      "Training epoch 9000 (took 161.70 sec, time left 0:02:40.472170 sec) loss 0.00008358\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChMgw2,5,10, 9000 epoch.pth\n",
      "Training epoch 10000 (took 161.41 sec, time left -1 day, 23:59:59.839287 sec) loss 0.00008356\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/ParametrizedClassifier//ChMgw2,5,10, 10000 epoch.pth\n",
      " ===================   END OF TRAIN   =================== \n"
     ]
    }
   ],
   "source": [
    "ModelPath = os.getcwd()\n",
    "\n",
    "model = OurModel([8, 32, 32, 32, 1], 'ReLU')\n",
    "model.SetNumberOfEpochs(int(1e4))\n",
    "model.SetInitialLearningRate(1e-3)\n",
    "model.SetSaveAfterEpoch([10, 50, 100, 500, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000])\n",
    "model.Report()\n",
    "\n",
    "Data, DataParameters = model.Preprocess(Data, DataParameters)\n",
    "Data, DataParameters = Data.float(), DataParameters.float()\n",
    "Labels, Weights = Labels.float(), Weights.float()\n",
    "\n",
    "model.cuda()\n",
    "print(torch.cuda.memory_allocated())\n",
    "Data, DataParameters = Data.cuda(), DataParameters.cuda()\n",
    "print(torch.cuda.memory_allocated())\n",
    "\n",
    "model.Train(Data, DataParameters, Labels, Weights, Name='/ChMgw2,5,10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Start: 145.0 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Start: %s MB\"%str((torch.cuda.memory_allocated()//1e6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture = [11, 32, 32, 32, 1]\n",
      "Activation function = ReLU\n",
      "Initial learning rate = 0.001\n",
      "Number of epochs = 100\n",
      "Saving network after epoch(s): [10, 50, 100]\n",
      "Setting up preprocess statistics.\n",
      "Before Start: 0.0 MB\n",
      "Putting Model on Cuda: 0.0 MB\n",
      "Putting Data on Cuda: 233.0 MB\n",
      "Putting Data on Cuda: 252.0 MB\n",
      " Making copies of Data ======== Memory: 252.0 MB ==================== \n",
      " x1 Computation =============== Memory: 252.0 MB ==================== \n",
      "Layer Memory: 252.0 MB =============== \n",
      "Layer Memory: 1491.0 MB =============== \n",
      "Layer Memory: 2730.0 MB =============== \n",
      " x2 Computation =============== Memory: 3988.0 MB ==================== \n",
      "Layer Memory: 3988.0 MB =============== \n",
      "Layer Memory: 5227.0 MB =============== \n",
      "Layer Memory: 6465.0 MB =============== \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 592.00 MiB (GPU 0; 7.92 GiB total capacity; 6.02 GiB already allocated; 559.75 MiB free; 19.57 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7cdff7ded065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Putting Data on Cuda: %s MB\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataParameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#model.Train(Data, DataParameters, Labels, Name='ChPgw2,5,10')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ParametrizedClassifier/Training.py\u001b[0m in \u001b[0;36mForward\u001b[0;34m(self, Data, DataParameters)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mLayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearLayerList2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Layer Memory: %s MB =============== \"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActivationFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutputLayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 592.00 MiB (GPU 0; 7.92 GiB total capacity; 6.02 GiB already allocated; 559.75 MiB free; 19.57 MiB cached)"
     ]
    }
   ],
   "source": [
    "ModelPath = os.getcwd()\n",
    "\n",
    "model = OurModel([11, 32, 32, 1], 'ReLU')\n",
    "model = model.double()\n",
    "model.SetNumberOfEpochs(int(1e2))\n",
    "model.SetInitialLearningRate(1e-3)\n",
    "model.SetSaveAfterEpoch([10, 50, 100])\n",
    "model.Report()\n",
    "\n",
    "Data, DataParameters = model.Preprocess(Data, DataParameters)\n",
    "\n",
    "print(\"Before Start: %s MB\"%str((torch.cuda.memory_allocated()//1e6)))\n",
    "model.cuda()\n",
    "print(\"Putting Model on Cuda: %s MB\"%str((torch.cuda.memory_allocated()//1e6)))\n",
    "Data, DataParameters = Data.cuda(), DataParameters.cuda()\n",
    "print(\"Putting Data on Cuda: %s MB\"%str(torch.cuda.memory_allocated()//1e6))\n",
    "Labels = Labels.cuda()\n",
    "print(\"Putting Data on Cuda: %s MB\"%str(torch.cuda.memory_allocated()//1e6))\n",
    "model.Forward(Data, DataParameters).size()\n",
    "\n",
    "#model.Train(Data, DataParameters, Labels, Name='ChPgw2,5,10')\n",
    "\n",
    "#Train(Data, DataParameters, Labels)\n",
    "print(\"After running Train func: %s MB\"%str(torch.cuda.memory_allocated()//1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture = [11, 32, 32, 1]\n",
      "Activation function = ReLU\n",
      "Initial learning rate = 0.001\n",
      "Number of epochs = 100\n",
      "Saving network after epoch(s): [10, 50, 100]\n",
      "Setting up preprocess statistics.\n",
      "Before Start: 0.0 MB\n",
      "Putting Model on Cuda: 0.0 MB\n",
      "Putting Data on Cuda: 233.0 MB\n",
      "Putting Data on Cuda: 252.0 MB\n",
      " Making copies of Data ======== Memory: 252.0 MB ==================== \n",
      " x1 Computation =============== Memory: 252.0 MB ==================== \n",
      "Layer Memory: 252.0 MB =============== \n",
      "Layer Memory: 1491.0 MB =============== \n",
      " x2 Computation =============== Memory: 2749.0 MB ==================== \n",
      "Layer Memory: 2749.0 MB =============== \n",
      "Layer Memory: 3988.0 MB =============== \n",
      "After running Train func: 252.0 MB\n"
     ]
    }
   ],
   "source": [
    "ModelPath = os.getcwd()\n",
    "\n",
    "model = OurModel([11, 32, 32, 1], 'ReLU')\n",
    "model = model.double()\n",
    "model.SetNumberOfEpochs(int(1e2))\n",
    "model.SetInitialLearningRate(1e-3)\n",
    "model.SetSaveAfterEpoch([10, 50, 100])\n",
    "model.Report()\n",
    "\n",
    "Data, DataParameters = model.Preprocess(Data, DataParameters)\n",
    "\n",
    "print(\"Before Start: %s MB\"%str((torch.cuda.memory_allocated()//1e6)))\n",
    "model.cuda()\n",
    "print(\"Putting Model on Cuda: %s MB\"%str((torch.cuda.memory_allocated()//1e6)))\n",
    "Data, DataParameters = Data.cuda(), DataParameters.cuda()\n",
    "print(\"Putting Data on Cuda: %s MB\"%str(torch.cuda.memory_allocated()//1e6))\n",
    "Labels = Labels.cuda()\n",
    "print(\"Putting Data on Cuda: %s MB\"%str(torch.cuda.memory_allocated()//1e6))\n",
    "model.Forward(Data, DataParameters).size()\n",
    "\n",
    "#model.Train(Data, DataParameters, Labels, Name='ChPgw2,5,10')\n",
    "\n",
    "#Train(Data, DataParameters, Labels)\n",
    "print(\"After running Train func: %s MB\"%str(torch.cuda.memory_allocated()//1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2419511])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weights.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
